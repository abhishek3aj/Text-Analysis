{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ans_feature_df = pd.read_csv('StackOverflowAndroidAnsweredFeaturesTotal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Id', 'PostTypeId', 'AcceptedAnswerId', 'ParentId',\n",
       "       'CreationDate', 'DeletionDate', 'Score', 'ViewCount', 'Body',\n",
       "       'OwnerUserId', 'OwnerDisplayName', 'LastEditorUserId',\n",
       "       'LastEditorDisplayName', 'LastEditDate', 'LastActivityDate', 'Title',\n",
       "       'Tags', 'AnswerCount', 'CommentCount', 'FavoriteCount', 'ClosedDate',\n",
       "       'CommunityOwnedDate', 'ParentId.1', 'first_response', 'number_of_days',\n",
       "       'lines_of_code', 'number_of_code_tags', 'average_sent_length',\n",
       "       'urls_count', 'sent_length', 'word_count', 'SBAR', 'SBARQ', 'SQ'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_ans_feature_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "def date_diff(first_response, CreationDate):\n",
    "    dt = parser.parse(first_response)\n",
    "    dt1 = parser.parse(CreationDate)\n",
    "    diff = dt - dt1\n",
    "    return diff.total_seconds()/3600 # divide by 3600 to convert to hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class(hr):\n",
    "    if 0 <= hr <= 1:\n",
    "        return 1\n",
    "    elif 1< hr <= 2:\n",
    "        return 2\n",
    "    elif 2< hr<= 4:\n",
    "        return 4\n",
    "    elif 4< hr <=10:\n",
    "        return 10;\n",
    "    elif hr > 10:\n",
    "        return 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_diff_list = []\n",
    "hr_y = []\n",
    "count ={}\n",
    "for index, row in total_ans_feature_df.iterrows():\n",
    "    hr_diff = date_diff(row['first_response'], row['CreationDate'])\n",
    "    hr_diff_list.append(hr_diff)\n",
    "    cls = get_class(hr_diff)\n",
    "    if cls in count:\n",
    "        count[cls] = count[cls]+ 1\n",
    "    else:\n",
    "        count[cls] = 1\n",
    "    hr_y.append(cls)\n",
    "    \n",
    "total_ans_feature_df['hr_diff'] = hr_diff_list\n",
    "total_ans_feature_df['y_hr'] = hr_y\n",
    "total_ans_feature_df = total_ans_feature_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "illegal target for annotation (<ipython-input-7-0a633c7f7e46>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-0a633c7f7e46>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    1:0.45\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m illegal target for annotation\n"
     ]
    }
   ],
   "source": [
    "count\n",
    "1:0.45\n",
    "2:0.9\n",
    "4:0.92\n",
    "10:0.93\n",
    "11:0.8\n",
    "    \n",
    "9270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>PostTypeId</th>\n",
       "      <th>AcceptedAnswerId</th>\n",
       "      <th>ParentId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>DeletionDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>Body</th>\n",
       "      <th>...</th>\n",
       "      <th>number_of_code_tags</th>\n",
       "      <th>average_sent_length</th>\n",
       "      <th>urls_count</th>\n",
       "      <th>sent_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>SBAR</th>\n",
       "      <th>SBARQ</th>\n",
       "      <th>SQ</th>\n",
       "      <th>hr_diff</th>\n",
       "      <th>y_hr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>54002492</td>\n",
       "      <td>1</td>\n",
       "      <td>54666886.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-01-02 07:05:39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;p&gt;how can i perform login without OTP verific...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1010.561944</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Id  PostTypeId  AcceptedAnswerId  ParentId  \\\n",
       "0           0  54002492           1        54666886.0       0.0   \n",
       "\n",
       "          CreationDate  DeletionDate  Score  ViewCount  \\\n",
       "0  2019-01-02 07:05:39           0.0      0         50   \n",
       "\n",
       "                                                Body  ...  \\\n",
       "0  <p>how can i perform login without OTP verific...  ...   \n",
       "\n",
       "   number_of_code_tags average_sent_length  urls_count sent_length word_count  \\\n",
       "0                    0                11.0           0           2         22   \n",
       "\n",
       "  SBAR SBARQ   SQ      hr_diff  y_hr  \n",
       "0  0.0   0.0  0.5  1010.561944    11  \n",
       "\n",
       "[1 rows x 37 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_ans_feature_df[8500:8600][['CreationDate','first_response','hr_diff', 'y_hr']]\n",
    "total_ans_feature_df[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "x = total_ans_feature_df[['lines_of_code', 'number_of_code_tags', 'average_sent_length',\n",
    "       'urls_count', 'sent_length', 'word_count', 'SBAR', 'SBARQ', 'SQ']]\n",
    "\n",
    "y = total_ans_feature_df['y_hr']\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=0.3, random_state=7)\n",
    "\n",
    "X_train[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=7, solver='lbfgs', multi_class='multinomial',class_weight={1:0.05,2:0.25,4:0.3,10:0.3,11:0.1}, max_iter=4000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1:0.45\n",
    "2:0.9\n",
    "4:0.92\n",
    "10:0.93\n",
    "11:0.8\n",
    "{1: 5102, 2: 920, 4: 712, 10: 664, 11: 1872}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre = clf.predict(X_test)\n",
    "pre\n",
    "# print (accuracy_score(y_test, pre))\n",
    "# print(classification_report(y_test, pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.472851492268968\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.80      0.67      1537\n",
      "           2       0.10      0.05      0.07       292\n",
      "           4       0.11      0.06      0.08       219\n",
      "          10       0.09      0.14      0.11       190\n",
      "          11       0.36      0.06      0.10       543\n",
      "\n",
      "   micro avg       0.47      0.47      0.47      2781\n",
      "   macro avg       0.25      0.22      0.20      2781\n",
      "weighted avg       0.42      0.47      0.41      2781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pre = clf.predict(X_test)\n",
    "print (accuracy_score(y_test, pre))\n",
    "print(classification_report(y_test, pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='linear', C=10,class_weight={1:0.05,2:0.25,4:0.3,10:0.3,11:0.1}).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = clf.predict(X_test)\n",
    "print (accuracy_score(y_test, pre))\n",
    "print(classification_report(y_test, pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = total_ans_feature_df[['lines_of_code', 'number_of_code_tags', 'average_sent_length',\n",
    "       'urls_count', 'sent_length', 'word_count', 'SBAR', 'SBARQ', 'SQ']]\n",
    "\n",
    "y = total_ans_feature_df['hr_diff']\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rms = sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.90143475522919"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVR(kernel='linear', C=1).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.14737396692193"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "y_pred = clf.predict(X_train)\n",
    "rms = sqrt(mean_squared_error(y_train, y_pred))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model\n",
    "\n",
    "poly = PolynomialFeatures(degree=5)\n",
    "X_ = poly.fit_transform(X_train)\n",
    "predict_ = poly.fit_transform(X_train)\n",
    "\n",
    "clf = linear_model.LinearRegression()\n",
    "clf.fit(X_, y_train)\n",
    "y_pred = clf.predict(predict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.3980617542366"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "# y_pred = clf.predict(X_train)\n",
    "rms = sqrt(mean_squared_error(y_train, y_pred))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Normalize total_bedrooms column\n",
    "normalized_X = preprocessing.normalize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.44565103 ... 0.         0.         0.02025687]\n",
      " [0.01585217 0.04755652 0.         ... 0.01056811 0.         0.        ]\n",
      " [0.23079075 0.06861347 0.08420743 ... 0.0053465  0.         0.        ]\n",
      " ...\n",
      " [0.46784712 0.03772961 0.08753269 ... 0.01131888 0.         0.00377296]\n",
      " [0.02216415 0.01108207 0.15293262 ... 0.01108207 0.         0.00277052]\n",
      " [0.         0.         0.31612552 ... 0.01234865 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print (normalized_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1010.561944\n",
      "1        999.480556\n",
      "2        875.291111\n",
      "3        896.880000\n",
      "4        855.983889\n",
      "5        855.314167\n",
      "6        803.234167\n",
      "7        772.374722\n",
      "8        800.926944\n",
      "9        785.583611\n",
      "10       785.031389\n",
      "11       784.035556\n",
      "12       743.839167\n",
      "13       712.019444\n",
      "14       725.888889\n",
      "15       727.263611\n",
      "16       722.474722\n",
      "17       697.970833\n",
      "18       688.804444\n",
      "19       714.852500\n",
      "20       690.010278\n",
      "21       673.671111\n",
      "22       664.290833\n",
      "23       670.561111\n",
      "24       666.151389\n",
      "25       641.008333\n",
      "26       652.090833\n",
      "27       659.636944\n",
      "28       621.829167\n",
      "29       631.132500\n",
      "           ...     \n",
      "9240       0.336944\n",
      "9241       0.487222\n",
      "9242       1.600278\n",
      "9243       0.679444\n",
      "9244       0.202500\n",
      "9245       3.454167\n",
      "9246       0.148333\n",
      "9247       0.062222\n",
      "9248       0.235000\n",
      "9249       0.039167\n",
      "9250       0.894722\n",
      "9251       0.379167\n",
      "9252       0.324722\n",
      "9253       1.929444\n",
      "9254       0.227500\n",
      "9255       0.500556\n",
      "9256       0.630833\n",
      "9257       0.578333\n",
      "9258       0.126111\n",
      "9259       0.553611\n",
      "9260       0.175000\n",
      "9261       0.046944\n",
      "9262       0.214167\n",
      "9263       0.893056\n",
      "9264       0.050556\n",
      "9265       0.212222\n",
      "9266       0.510278\n",
      "9267       0.131944\n",
      "9268       0.137222\n",
      "9269       1.442500\n",
      "Name: hr_diff, Length: 9270, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = total_ans_feature_df[['lines_of_code', 'number_of_code_tags', 'average_sent_length',\n",
    "       'urls_count', 'sent_length', 'word_count', 'SBAR', 'SBARQ', 'SQ']]\n",
    "\n",
    "y = total_ans_feature_df['hr_diff']\n",
    "\n",
    "normalized_X = preprocessing.normalize(x)\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(normalized_X, y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.02058899131256"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rms = sqrt(mean_squared_error(y_test, y_pred))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
